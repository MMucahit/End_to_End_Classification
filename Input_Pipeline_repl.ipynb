{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`tf.dataset` Input Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_sales_numbers = [21, 22, -100, 31, -1, 32, 34, 31]\n",
    "tf_dataset = tf.data.Dataset.from_tensor_slices(daily_sales_numbers)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert Into ``Numpy Array``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([x for x in tf_dataset.as_numpy_iterator()])\n",
    "\n",
    "print([x.numpy() for x in tf_dataset])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Take` As Much Data As You Want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x for x in tf_dataset.take(5)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Filter` Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_filtered_dataset = tf_dataset.filter(lambda x : x > 0)\n",
    "\n",
    "[x for x in tf_filtered_dataset]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform Data With `Map` Fucntion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_transformed_dataset = tf_filtered_dataset.map(lambda x: x * 20)\n",
    "\n",
    "[x for x in tf_transformed_dataset]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Shuffle` Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_shuffled_data = tf_transformed_dataset.shuffle(buffer_size=3)\n",
    "\n",
    "[x for x in tf_shuffled_data]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Batch` Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_batched_data = tf_transformed_dataset.batch(2)\n",
    "\n",
    "[x for x in tf_batched_data]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_dataset = tf.data.Dataset.from_tensor_slices(daily_sales_numbers)\n",
    "\n",
    "## All the steps in one single line that is Input Pipeline\n",
    "tf_dataset = tf_dataset.filter(lambda x: x > 0).map(lambda y: y * 20).shuffle(2).batch(2)\n",
    "\n",
    "[i for i in tf_dataset]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read Data With `tf.data.Dataset.list_file`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_label(file_path):\n",
    "    import os\n",
    "    return tf.strings.split(file_path, os.path.sep)[-2]\n",
    "\n",
    "def process_image(file_path):\n",
    "    label = get_label(file_path)\n",
    "\n",
    "    img = tf.io.read_file(file_path)\n",
    "    img = tf.image.decode_jpeg(img)\n",
    "    img = tf.image.resize(img, [128, 128]) ## Resize\n",
    "    img = img / 255 ## Scale\n",
    "\n",
    "    return img, label\n",
    "\n",
    "image_ds = tf.data.Dataset.list_files('PlantVillage/*/*', shuffle=False)\n",
    "image_ds = image_ds.shuffle(320)\n",
    "\n",
    "[(image, label) for image, label in image_ds.map(process_image).take(10)]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read Data with `tf.keras.utils.image_dataset_from_directory`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "img_height = 180\n",
    "img_weight = 180\n",
    "\n",
    "train_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    'PlantVillage/',\n",
    "    validation_split=0.2,\n",
    "    subset='training',\n",
    "    seed=55,\n",
    "    image_size=(img_height, img_weight),\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "val_ds = tf.keras.utils.image_dataset_from_directory(\n",
    "    'PlantVillage/',\n",
    "    validation_split=0.2,\n",
    "    subset='validation',\n",
    "    seed=55,\n",
    "    image_size=(img_height, img_weight),\n",
    "    batch_size=batch_size\n",
    ")\n",
    "\n",
    "scale_train_ds= train_ds.map(lambda x, y: (x / 255, y))\n",
    "scale_val_ds = val_ds.map(lambda x, y: (x /255, y))\n",
    "\n",
    "[i for i in scale_train_ds.take(5)] ## 5 Batch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
